{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:/Users/Jorge Pay√†/Desktop/4Geeks/Final Project/Code/DGA-Detection-project2/data/\n",
    "import streamlit as st\n",
    "import tldextract\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pickle import load, dump\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "def extract_subdomain_and_domain(host):\n",
    "    ext = tldextract.extract(host)\n",
    "    return ext.domain if ext.subdomain == '' else '.'.join([ext.subdomain, ext.domain])\n",
    "\n",
    "def get_domain_length(host):\n",
    "    return len(host)\n",
    "\n",
    "def unique_char_count(host):\n",
    "    return len(set(host))\n",
    "\n",
    "def unique_letter_count(host):\n",
    "    return len(set(re.sub(r'[^a-z]', '', host)))\n",
    "\n",
    "def unique_digit_count(host):\n",
    "    return len(set(re.sub(r'[^0-9]', '', host)))\n",
    "\n",
    "def letter_ratio(host):\n",
    "    letters = re.sub(r'[^a-z]', '', host)\n",
    "    return len(letters) / len(host) if host else 0\n",
    "\n",
    "def digit_ratio(host):\n",
    "    digits = re.sub(r'[^0-9]', '', host)\n",
    "    return len(digits) / len(host) if host else 0\n",
    "\n",
    "def unique_letter_ratio(host):\n",
    "    letters = re.sub(r'[^a-z]', '', host)\n",
    "    return len(set(letters)) / len(set(host)) if host else 0\n",
    "\n",
    "def unique_digit_ratio(host):\n",
    "    digits = re.sub(r'[^0-9]', '', host)\n",
    "    return len(set(digits)) / len(set(host)) if host else 0\n",
    "\n",
    "def special_char_ratio(host):\n",
    "    special_chars = re.sub(r'[a-z0-9]', '', host)\n",
    "    return len(special_chars) / len(host) if host else 0\n",
    "\n",
    "def consonant_ratio(host):\n",
    "    consonants = sum(1 for char in host if char.isalpha() and char.lower() not in 'aeiou')\n",
    "    return consonants / len(host) if host else 0\n",
    "\n",
    "def vowel_ratio(host):\n",
    "    vowels = sum(1 for char in host if char.lower() in 'aeiou')\n",
    "    return vowels / len(host) if host else 0\n",
    "\n",
    "def longest_consonant_string(host):\n",
    "    consonants = 'bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ'\n",
    "    max_length = 0\n",
    "    current_length = 0\n",
    "    for char in host:\n",
    "        if char in consonants:\n",
    "            current_length += 1\n",
    "            max_length = max(max_length, current_length)\n",
    "        else:\n",
    "            current_length = 0\n",
    "    return max_length\n",
    "\n",
    "def longest_vowel_string(host):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    max_length = 0\n",
    "    current_length = 0\n",
    "    for char in host:\n",
    "        if char in vowels:\n",
    "            current_length += 1\n",
    "            max_length = max(max_length, current_length)\n",
    "        else:\n",
    "            current_length = 0\n",
    "    return max_length\n",
    "\n",
    "def longest_number_string(host):\n",
    "    numbers = '0123456789'\n",
    "    max_length = 0\n",
    "    current_length = 0\n",
    "    for char in host:\n",
    "        if char in numbers:\n",
    "            current_length += 1\n",
    "            max_length = max(max_length, current_length)\n",
    "        else:\n",
    "            current_length = 0\n",
    "    return max_length\n",
    "\n",
    "def entropy(host):\n",
    "    p, lns = Counter(host), float(len(host))\n",
    "    return -sum( count/lns * np.log2(count/lns) for count in p.values())\n",
    "\n",
    "\n",
    "stopwords = load(open('../data/raw/top_english_words.pkl', 'rb'))\n",
    "dict_freq = { word[0]: num for num, word in enumerate(stopwords.values, 1) }\n",
    "\n",
    "def ngrams(word, n):\n",
    "    l_ngrams = []\n",
    "    n = n if isinstance(n, list) else [n]\n",
    "    word = word if isinstance(word, list) else [word]\n",
    "\n",
    "    for w in word:\n",
    "        for curr_n in n:\n",
    "            ngrams = [w[i:i+curr_n] for i in range(0,len(w)-curr_n+1)]\n",
    "            l_ngrams.extend(ngrams)\n",
    "    return l_ngrams\n",
    "\n",
    "def ngram_feature(host, n):\n",
    "    l_ngrams = ngrams(host, n)\n",
    "    count_sum = sum(dict_freq.get(ngram, 0) for ngram in l_ngrams)\n",
    "    feature = count_sum/(len(host)-n+1) if len(host)-n+1 else 0\n",
    "    return feature\n",
    "\n",
    "def average_ngram_feature(l_ngram_feature):\n",
    "    return sum(l_ngram_feature)/len(l_ngram_feature) if l_ngram_feature else 0\n",
    "\n",
    "\n",
    "model = load(open('../models/xgb_clf_opt.pkl', 'rb'))\n",
    "\n",
    "st.title(\"DGA Detector\")\n",
    "host = st.text_input(\"Enter domain name:\")\n",
    "df = pd.DataFrame([])\n",
    "\n",
    "if st.button(\"Is it legit or DGA-generated?\"):\n",
    "    domain = extract_subdomain_and_domain(host)\n",
    "    df['long_consonant_str'] = [longest_consonant_string(domain)]\n",
    "    df['unique_char_count'] = [unique_char_count(domain)]\n",
    "    df['entropy'] = [entropy(domain)]\n",
    "    df['vowel_ratio'] = [vowel_ratio(domain)]\n",
    "    df['unique_letter_count'] = [unique_letter_count(domain)]\n",
    "    df['d_length'] = [get_domain_length(domain)]\n",
    "    df['consonant_ratio'] = [consonant_ratio(domain)]\n",
    "    df['unique_digit_count'] = [unique_digit_count(domain)]\n",
    "    df['ngrams'] = [average_ngram_feature([ngram_feature(domain, n) for n in [1,2,3]])]\n",
    "    \n",
    "    prediction = model.predict(df)\n",
    "    if prediction[0] == 1:\n",
    "        st.write(\"This is DGA-generated\")\n",
    "    else:\n",
    "        st.write(\"This is a legit domain\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import streamlit as st\n",
    "# import tldextract\n",
    "# import regex as re\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from pickle import load, dump\n",
    "# from collections import Counter\n",
    "\n",
    "\n",
    "# def extract_subdomain_and_domain(host):\n",
    "#     ext = tldextract.extract(host)\n",
    "#     return ext.domain if ext.subdomain == '' else '.'.join([ext.subdomain, ext.domain])\n",
    "\n",
    "# def get_domain_length(host):\n",
    "#     return len(host)\n",
    "\n",
    "# def unique_char_count(host):\n",
    "#     return len(set(host))\n",
    "\n",
    "# def unique_letter_count(host):\n",
    "#     return len(set(re.sub(r'[^a-z]', '', host)))\n",
    "\n",
    "# def unique_digit_count(host):\n",
    "#     return len(set(re.sub(r'[^0-9]', '', host)))\n",
    "\n",
    "# def consonant_ratio(host):\n",
    "#     consonants = sum(1 for char in host if char.isalpha() and char.lower() not in 'aeiou')\n",
    "#     return consonants / len(host) if host else 0\n",
    "\n",
    "# def vowel_ratio(host):\n",
    "#     vowels = sum(1 for char in host if char.lower() in 'aeiou')\n",
    "#     return vowels / len(host) if host else 0\n",
    "\n",
    "# def longest_consonant_string(host):\n",
    "#     consonants = 'bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ'\n",
    "#     max_length = 0\n",
    "#     current_length = 0\n",
    "#     for char in host:\n",
    "#         if char in consonants:\n",
    "#             current_length += 1\n",
    "#             max_length = max(max_length, current_length)\n",
    "#         else:\n",
    "#             current_length = 0\n",
    "#     return max_length\n",
    "\n",
    "# def entropy(host):\n",
    "#     p, lns = Counter(host), float(len(host))\n",
    "#     return -sum( count/lns * np.log2(count/lns) for count in p.values())\n",
    "\n",
    "\n",
    "# stopwords = load(open('../data/raw/top_english_words.pkl', 'rb'))\n",
    "# dict_freq = { word[0]: num for num, word in enumerate(stopwords.values, 1) }\n",
    "\n",
    "# def ngrams(word, n):\n",
    "#     l_ngrams = []\n",
    "#     n = n if isinstance(n, list) else [n]\n",
    "#     word = word if isinstance(word, list) else [word]\n",
    "\n",
    "#     for w in word:\n",
    "#         for curr_n in n:\n",
    "#             ngrams = [w[i:i+curr_n] for i in range(0,len(w)-curr_n+1)]\n",
    "#             l_ngrams.extend(ngrams)\n",
    "#     return l_ngrams\n",
    "\n",
    "# def ngram_feature(host, n):\n",
    "#     l_ngrams = ngrams(host, n)\n",
    "#     count_sum = sum(dict_freq.get(ngram, 0) for ngram in l_ngrams)\n",
    "#     feature = count_sum/(len(host)-n+1) if len(host)-n+1 else 0\n",
    "#     return feature\n",
    "\n",
    "# def average_ngram_feature(l_ngram_feature):\n",
    "#     return sum(l_ngram_feature)/len(l_ngram_feature) if l_ngram_feature else 0\n",
    "\n",
    "\n",
    "# model = load(open('../models/xgb_clf_opt.pkl', 'rb'))\n",
    "\n",
    "# st.title(\"DGA Detector\")\n",
    "# host = st.text_input(\"Enter domain name:\")\n",
    "# df = pd.DataFrame([])\n",
    "\n",
    "# if st.button(\"Is it legit or DGA-generated?\"):\n",
    "#     domain = extract_subdomain_and_domain(host)\n",
    "#     df['long_consonant_str'] = [longest_consonant_string(domain)]\n",
    "#     df['unique_char_count'] = [unique_char_count(domain)]\n",
    "#     df['entropy'] = [entropy(domain)]\n",
    "#     df['vowel_ratio'] = [vowel_ratio(domain)]\n",
    "#     df['unique_letter_count'] = [unique_letter_count(domain)]\n",
    "#     df['d_length'] = [get_domain_length(domain)]\n",
    "#     df['consonant_ratio'] = [consonant_ratio(domain)]\n",
    "#     df['unique_digit_count'] = [unique_digit_count(domain)]\n",
    "#     df['ngrams'] = [average_ngram_feature([ngram_feature(domain, n) for n in [1,2,3]])]\n",
    "    \n",
    "#     prediction = model.predict(df)\n",
    "#     if prediction[0] == 1:\n",
    "#         st.write(\"This is DGA-generated\")\n",
    "#     else:\n",
    "#         st.write(\"This is a legit domain\")\n",
    "    \n",
    "# # The app is ready to use\n",
    "# # We can enter a domain name and the app will tell us if it is DGA-generated or not\n",
    "# # We can test the model with the domains we used before\n",
    "# # We can also test the model with other domains to see how the model performs with unseen data\n",
    "# # The app will show us the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import sqlite3\n",
    "\n",
    "# df = pd.read_csv('/workspaces/DGA-Detection-final/data/raw/dga_data_full.csv')\n",
    "# df = df.drop(columns=['domain', 'subclass'])\n",
    "# df.head()\n",
    "\n",
    "# # Create a subset of the data \n",
    "# df_legit = df[df['isDGA'] == 'legit']\n",
    "# df_dga = df[df['isDGA'] == 'dga']\n",
    "# df_legit_subset = df_legit.sample(n=100, random_state=42)\n",
    "# df_dga_subset = df_dga.sample(n=100, random_state=42)\n",
    "# df_subset = pd.concat([df_legit_subset, df_dga_subset])\n",
    "# df_subset = df_subset.reset_index(drop=True)\n",
    "# df_subset = df_subset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# df_subset.to_csv('/workspaces/DGA-Detection-final/data/processed/dga_data_subset.csv', index=False)\n",
    "\n",
    "# conn = sqlite3.connect('/workspaces/DGA-Detection-final/data/processed/dga_data_subset.db')\n",
    "# df_subset.to_sql('dga_data_subset', conn, if_exists='replace', index=False)\n",
    "\n",
    "# def show_legit_domain():\n",
    "#     conn = sqlite3.connect('/workspaces/DGA-Detection-final/data/processed/dga_data_subset.db')\n",
    "#     query = 'SELECT * FROM dga_data_subset WHERE isDGA=\"legit\" ORDER BY RANDOM() LIMIT 1'\n",
    "#     df = pd.read_sql(query, conn)\n",
    "#     return df\n",
    "\n",
    "# def show_dga_domain():\n",
    "#     conn = sqlite3.connect('/workspaces/DGA-Detection-final/data/processed/dga_data_subset.db')\n",
    "#     query = 'SELECT * FROM dga_data_subset WHERE isDGA=\"dga\" ORDER BY RANDOM() LIMIT 1'\n",
    "#     df = pd.read_sql(query, conn)\n",
    "#     return df\n",
    "\n",
    "# # Let's test the functions\n",
    "# print(show_legit_domain())\n",
    "# print(show_dga_domain())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
